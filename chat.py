import os
import google.generativeai as genai
import json
from get_namuwiki_docs import load_namuwiki_docs_selenium
from langchain.schema import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
import streamlit as st

# with open("key.json", 'r') as file:
#     data = json.load(file)
    
# gemini_api_key = data.get("gemini-key")pip 

# TODO: ì•„ë˜ YOUR-HUGGINGFACE-API-KEYë‘ OUR-GEMINI-API-KEYì— ìê¸°êº¼ ë„£ê¸°
if not os.environ.get("HUGGINGFACEHUB_API_TOKEN"):
    os.environ["HUGGINGFACEHUB_API_TOKEN"] = "you are Secret key"    
gemini_api_key = "you are Secret key"


genai.configure(api_key=gemini_api_key)

# gemini ëª¨ë¸ ë¡œë“œ 
def load_model():
    with st.spinner("ëª¨ë¸ì„ ë¡œë”©í•˜ëŠ” ì¤‘..."):
        gemini_model = genai.GenerativeModel('gemini-1.5-flash')
    print("Model loaded...")
    return gemini_model

# ì„ë² ë”© ë¡œë“œ
def load_embedding():
    with st.spinner("ì„ë² ë”©ì„ ë¡œë”©í•˜ëŠ” ì¤‘..."):
        embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    
    print("Embedding loaded...")
    return embedding

# Faiss vector DB ìƒì„±
def create_vectorstore(topic):     
    with st.spinner("ë‚˜ë¬´ìœ„í‚¤ì—ì„œ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
        # text = load_namuwiki_docs_selenium(topic)        
        # st.write(f"ì°¾ì€ ë¬¸ì„œ ì˜ˆì‹œ:\n{text[:100]}")
     # text = db.load()

        text = """
ìœ„í‚¤ë…ìŠ¤
ìœ„í‚¤
ë¸”ë¡œê·¸
 ë¡œê·¸ì¸
ìœ„í‚¤ë…ìŠ¤
ìœ„í‚¤ë…ìŠ¤ëŠ” ì˜¨ë¼ì¸ ì±…ì„ ì œì‘ ê³µìœ í•˜ëŠ” í”Œë«í¼ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.


 ìœ„í‚¤ë…ìŠ¤ ì˜µì‹œë””ì–¸ í”ŒëŸ¬ê·¸ì¸ ì˜¤í”ˆ! (2024ë…„ 11ì›” 30ì¼)
 ë¸”ë¡œê·¸ ì„œë¹„ìŠ¤ ì˜¤í”ˆ (2024ë…„ 11ì›”)
 ë‹¤í¬ëª¨ë“œ ê¸°ëŠ¥ ì¶”ê°€ (2024ë…„ 8ì›”)

ì¶”ì²œì±…
ê³µê°œì±…
ì „ìì±…
ì±…ì œëª© ë˜ëŠ” ì§€ì€ì´ë¥¼ ì…ë ¥í•˜ì„¸ìš”
â€» ìœ„í‚¤ë…ìŠ¤ì— ê³µê°œëœ ì±…ì…ë‹ˆë‹¤. (5í˜ì´ì§€ ì´ìƒì˜ ì±…ë“¤ë§Œ ë…¸ì¶œë©ë‹ˆë‹¤.)
1
ì í”„ íˆ¬ íŒŒì´ì¬
- ë°•ì‘ìš©
- 2025ë…„ 01ì›” 13ì¼
- 
- e-book
2
ë”¥ ëŸ¬ë‹ì„ ì´ìš©í•œ ìì—°ì–´ ì²˜ë¦¬ ì…ë¬¸
- Bryce ì™¸ 1ëª…
- 2025ë…„ 01ì›” 18ì¼
- 
- e-book
3
íŒŒì´ì¬ìœ¼ë¡œ ë°°ìš°ëŠ” ì•Œê³ ë¦¬ì¦˜ íŠ¸ë ˆì´ë”© (ê°œì •íŒ-2ì‡„)
- ì¡°ëŒ€í‘œ ì™¸ 1ëª…
- 2023ë…„ 05ì›” 30ì¼
- 
4
ë”¥ ëŸ¬ë‹ íŒŒì´í† ì¹˜ êµê³¼ì„œ - ì…ë¬¸ë¶€í„° íŒŒì¸íŠœë‹ê¹Œì§€
- Bryce ì™¸ 1ëª…
- 2025ë…„ 01ì›” 17ì¼
- 
- e-book


5
ì í”„ íˆ¬ ìë°”
- ë°•ì‘ìš©
- 2024ë…„ 12ì›” 08ì¼
- 
- e-book
6
<ë­ì²´ì¸LangChain ë…¸íŠ¸> - LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ğŸ‡°ğŸ‡·
- í…Œë””ë…¸íŠ¸
- 2025ë…„ 01ì›” 16ì¼
- 
7
ì£¼ì‹ ì‹œì¥ì„ ì´ê¸°ëŠ” ë§ˆë²•ì˜ ìë™ë§¤ë§¤
- ì—‘ìŠ¬ë¡ 
- 2023ë…„ 12ì›” 18ì¼
- 
8
ì™•ì´ˆë³´ë¥¼ ìœ„í•œ Python: ì‰½ê²Œ í’€ì–´ ì“´ ê¸°ì´ˆ ë¬¸ë²•ê³¼ ì‹¤ìŠµ
- ì „ë‡Œí•´ì»¤
- 2024ë…„ 10ì›” 08ì¼
- 
- e-book
9
[ ë¬¸ê³¼ìƒë„ í•  ìˆ˜ ìˆëŠ” ] íŒŒì´ì¬ ì—…ë¬´ ìë™í™” ì¼ì˜ëŸ¬ ë˜ê¸° + ì±—GPT
- ë©”ì´í—ˆ
- 2024ë…„ 12ì›” 22ì¼
- 
10
ë¯¸ìš´ì½”ë”©ìƒˆë¼: 4ì‹œê°„ë§Œì— ëë‚´ëŠ” íŒŒì´ì¬ ê¸°ì´ˆ
- ê¹€ì™¼ì†ê³¼ ì§‘ë‹¨ì§€ì„±ë“¤
- 2018ë…„ 05ì›” 22ì¼
- 
11
ì´ˆë³´ìë¥¼ ìœ„í•œ íŒŒì´ì¬ 300ì œ
- ì¡°ëŒ€í‘œ ì™¸ 1ëª…
- 2024ë…„ 06ì›” 23ì¼
- 
12
PyQt5 Tutorial - íŒŒì´ì¬ìœ¼ë¡œ ë§Œë“œëŠ” ë‚˜ë§Œì˜ GUI í”„ë¡œê·¸ë¨
- Dardao
- 2021ë…„ 05ì›” 19ì¼
- 


13
ì‚¬ì¥ë‹˜ ëª°ë˜ í•˜ëŠ” íŒŒì´ì¬ ì—…ë¬´ìë™í™”(ë¶€ì œ : ë“¤í‚¤ë©´ ì¼ ë§ì•„ì§)
- ì •ìš©ë²”, ì†ìƒìš° ì™¸ 1ëª…
- 2024ë…„ 08ì›” 27ì¼
- 
14
[Python ì™„ì „ì •ë³µ ì‹œë¦¬ì¦ˆ] 2í¸ : Pandas DataFrame ì™„ì „ì •ë³µ
- ê¹€íƒœì¤€
- 2022ë…„ 03ì›” 14ì¼
- 
15
íŒŒì´ì¬ì„ ì´ìš©í•œ ë¹„íŠ¸ì½”ì¸ ìë™ë§¤ë§¤ (ê°œì •íŒ)
- ì¡°ëŒ€í‘œ ì™¸ 1ëª…
- 2023ë…„ 01ì›” 13ì¼
- 
16
ì í”„ íˆ¬ ì¥ê³ 
- ë°•ì‘ìš©
- 2024ë…„ 12ì›” 10ì¼
- 
- e-book
17
Machine Learning ê°•ì˜ë…¸íŠ¸
- ë°•ìˆ˜ì§„
- 2021ë…„ 09ì›” 30ì¼
- 
18
ìœ„í‚¤ë…ìŠ¤
- ë°•ì‘ìš© ì™¸ 1ëª…
- 2025ë…„ 01ì›” 22ì¼
- 
19
C++ ì´ì•¼ê¸°(A Story of C++)
- SEADOG
- 2024ë…„ 12ì›” 02ì¼
- 
20
Must Learning with R (ê°œì •íŒ)
- DoublekPark ì™¸ 1ëª…
- 2023ë…„ 02ì›” 22ì¼
- 
ì´ì „12345...76ë‹¤ìŒ

ë¸”ë¡œê·¸ ì†Œì‹
TG_Miniapp
 0
í…”ë ˆê·¸ë¨ ë¯¸ë‹ˆì•± ìŠ¤í† ì–´
1. í…”ë ˆê·¸ë¨ ì•±ì„¼í„° http://t.me/tappsbot 2. íŒŒì¸ë“œ ë¯¸ë‹ˆì•± https://www.findmini.app/ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¯¸ë‹ˆì•± ë¶„ë¥˜ í•´ì£¼ëŠ” ì›¹ì‚¬ì´íŠ¸ í…”ë ˆê·¸ë¨ë´‡ : â€¦

3ì‹œê°„ ì „
 5  0  0
í‚¤ëª¨
 2
C# &, |ì™€ &&, ||ì˜ ì°¨ì´
1. & (ë¹„íŠ¸ AND) - ëª¨ë“  ì¡°ê±´ì„ ë¬´ì¡°ê±´ í‰ê°€(ì²« ë²ˆì§¸ ì¡°ê±´ì´ falseì´ì—¬ë„ ë‘ë²ˆì§¸ ì¡°ê±´ì„ í™•ì¸í•œë‹¤) â€¦

10ì‹œê°„ ì „
 46  0  0
TG_Miniapp
 0
í…”ë ˆê·¸ë¨ ë¯¸ë‹ˆì•±ê³¼ ì›¹3 ì—°ë™
ì‚¬ë¡€ 5 1. bums : http://app.bums.bot http://t.me/bums 2. w-coin : https://w-coin.io http://t.me/wcointapbot 3. tapswap : â€¦

14ì‹œê°„ ì „
 9  0  0
ITê¸°ìˆ ê³µìœ 
 3
Blog Image
ìˆ«ì ë§ì¶”ê¸° ê²Œì„ ë§Œë“¤ê¸° - C# í”„ë¡œê·¸ë˜ë°
â˜… ìˆ«ì ë§ì¶”ê¸° ê²Œì„ ìˆ«ì ë§ì¶”ê¸° ê²Œì„ì€ ì„ì˜ë¡œ ìƒì„±ëœ ìˆ«ìë¥¼ ì •í•´ì§„ íšŸìˆ˜ ë‚´ì— ë§ì¶”ëŠ” ê²Œì„ì…ë‹ˆë‹¤. â€¦

1ì¼ ì „
 31  1  0
ITê¸°ìˆ ê³µìœ 
 3
Blog Image
ë¡œê·¸ì¸ ì°½ ë§Œë“¤ê¸° - C# í”„ë¡œê·¸ë˜ë°
â˜… ë¡œê·¸ì¸ ì¸í„°ë„· í™˜ê²½ì—ì„œ ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í•˜ë ¤ë©´ íšŒì› ê°€ì…ê³¼ ë¡œê·¸ì¸ì€ í•„ìˆ˜ì…ë‹ˆë‹¤. ì´ë©”ì¼, ì‚¬ì§„ ì €ì¥ì†Œ, ì‡¼í•‘ëª°, SNS(ì†Œì…œ â€¦

1ì¼ ì „
 51  1  0
ITê¸°ìˆ ê³µìœ 
 3
Blog Image
ì²« ìœˆí¼(WinForm) ë§Œë“¤ê¸° - C# í”„ë¡œê·¸ë˜ë°
â˜… ìœˆí¼(WinForms) ìœˆí¼(WinForms)ì€ ìœˆë„ìš°ì¦ˆ í¼(Windows Forms)ì˜ ë‹¨ì¶•ì–´ ì´ë©°, ìœˆë„ìš°ì¦ˆ ê¸°ë°˜ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤(UI, User Interface) ì• í”Œë¦¬ì¼€ì´ì…˜ì„ â€¦

1ì¼ ì „
 36  1  0
ë²„ë“¤ê°•ì•„ì§€
 0
ì›¹í¬ë¡¤ë§
https://wikidocs.net/blog/@systrader79/1347/?fbclid=IwY2xjawH9hE5leHRuA2FlbQIxMAABHd5O4JGpsfrZZfG95uVfURqcLlAdtbkgXK9v8Z8l8WQVtihJmfyEQbNyAaem026eSz8BOIqGnUtFt9HugQ

1ì¼ ì „
 24  0  0
ë¦¬ë¹—ëŒ€í•™
 1
Blog Image
[ì •ë³´ê³µìœ ] ê°€ì‹œë‹¤_AWS EKS Hands-on Study ëª¨ì§‘
AWS, í´ë¼ìš°ë“œ ê´€ë ¨ í•´ì„œ ìœ ëª…í•˜ì‹  ê°€ì‹œë‹¤ë‹˜ì´ ìŠ¤í„°ë””ë¥¼ ëª¨ì§‘ì¤‘ì¸ê²ƒê°™ìŠµë‹ˆë‹¤. CKA ìê²©ì¦ì„ ì¤€ë¹„ì¤‘ì´ë¼ì„œ, ì €ëŠ” ì°¸ì—¬ê°€ ì–´ë µì§€ë§Œ ê¸°íšŒë˜ì‹œëŠ”ë¶„ì€ â€¦

1ì¼ ì „
 26  0  0
ì „ë‡Œí•´ì»¤
 1
Blog Image
OpenAI í”Œë ˆì´ê·¸ë¼ìš´ë“œì—ì„œ ë§¤ê°œë³€ìˆ˜ ì¡°ì •í•˜ê¸°
â€» ë„ì„œ ì¦ì • ì´ë²¤íŠ¸ ì•ˆë‚´ ìœ„í‚¤ë…ìŠ¤ì˜ â€œì¶œíŒì‚¬ì™€ í•¨ê»˜í•˜ëŠ” ë„ì„œ ì¦ì • ì´ë²¤íŠ¸â€ë¥¼ í†µí•´ âŸªOpenAI, êµ¬ê¸€ Gemini, â€¦

2ì¼ ì „
 46  0  0
systrader79ì˜ íŠ¸ë ˆì´ë”© ì´ì•¼ê¸°
 7
Blog Image
ìì—°ì–´ë¡œ ì½”ë”©ì—†ì´ ì›¹í¬ë¡¤ë§ í•˜ëŠ” ë°©ë²• - firecrawl
AIê°€ ì •ë§ ì„¸ìƒì„ ì—„ì²­ë‚˜ê²Œ ë³€í™”ì‹œí‚¤ê³  ìˆìŠµë‹ˆë‹¤. ì—¬ëŸ¬ë¶„ë„ ì›¹ í¬ë¡¤ë§ì´ë¼ëŠ” ìš©ì–´ë¥¼ ë“¤ì–´ë³´ì‹  ì ì´ ìˆìœ¼ì‹¤ ê²ë‹ˆë‹¤. ìš°ë¦¬ê°€ â€¦

2ì¼ ì „
 633  1  2
ì¦ê±°ìš´ìš©
 0
Blog Image
Springboot í”„ë¡œì íŠ¸ ìƒì„±/ì„¤ì •
ì—¬ê¸°ì— ê°„í¸í•˜ê²Œ í”„ë¡œì íŠ¸ë¥¼ ë§Œë“¤ìˆ˜ ìˆë„ë¡ ë•ëŠ” ì‚¬ì´íŠ¸ê°€ ìˆìŠµë‹ˆë‹¤. https://start.spring.io/ ì—¬ê¸°ì„œ ë³´ì…”ì•¼ í•˜ëŠ”ê²ƒë“¤ì— ëŒ€í•œ ì„¤ëª…ì…ë‹ˆë‹¤. Project â€¦

2ì¼ ì „
 34  0  0
TG_Miniapp
 0
ChatGPT ë¯¸ë‹ˆì•±
ì±—GPTì™€ ì—°ê³„ëœ í…”ë ˆê·¸ë¨ ë¯¸ë‹ˆì•± ì´ë‹¤. http://t.me/JugemuAIBot í…ŒìŠ¤í¬íˆ¬ì–¸(ì±—GPT), íƒ­íˆ¬ì–¸, í†¤íˆ¬ì–¸ì´ ìˆê³ , íƒ€ì„íˆ¬ì–¸ì€ ì—†ë‹¤.

3ì¼ ì „
 30  0  0

Â©2008 â€¢ ìœ„í‚¤ë…ìŠ¤ â€¢ ê°œì¸ì •ë³´ì·¨ê¸‰ë°©ì¹¨ â€¢ ì„œë¹„ìŠ¤ì•½ê´€ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸ : 724-14-01849 | ëŒ€í‘œìëª…: ë°•ì‘ìš© | í†µì‹ íŒë§¤ì‹ ê³ : 2022-ê²½ê¸°ê³¼ì²œ-0278 | ë¬¸ì˜: pahkey@gmail.com
"""
        
    if text:        
        paragraphs = text.split("\n\n")[:-1] if "\n\n" in text else text.split("\n") # ì¡°ê¸ˆ ë” ë””í…Œì¼í•˜ê²Œ ìˆ˜ì •í•˜ê¸° 
    else:
        paragraphs = []    
        
    # FAISS ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
    with st.spinner("ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘..."): 
        # convert to Document object (required for LangChain)
        documents = [Document(page_content=doc, metadata={"source": f"doc{idx+1}"}) for idx, doc in enumerate(paragraphs)]
        
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        splits = text_splitter.split_documents(documents)    
        
        vectorstore = FAISS.from_documents(documents=splits, embedding=st.session_state.embedding)
        
    return vectorstore

# RAG using prompt
def rag_chatbot(question):
    context_docs = st.session_state.vectorstore.similarity_search(question, k=2)
    # for i, doc in enumerate(context_docs):
    #     st.write(f"{i+1}ë²ˆì§¸ ë¬¸ì„œ: {doc.page_content}")
        
    context_docs = "\n\n".join([f"{i+1}ë²ˆì§¸ ë¬¸ì„œ:\n{doc.page_content}" for i, doc in enumerate(context_docs)])

    # prompt = f"Context: {context_docs}\nQuestion: {question}\nAnswer in a complete sentence:"
    prompt = f"ë¬¸ë§¥: {context_docs}\nì§ˆë¬¸: {question}\në‹µë³€:" 
    # response = gemini_model(prompt)
    
    response = st.session_state.model.generate_content(prompt)
    answer = response.candidates[0].content.parts[0].text

    print("ì¶œì²˜ ë¬¸ì„œ:", context_docs)
    return answer, context_docs


# Streamlit ì„¸ì…˜ì—ì„œ ëª¨ë¸ì„ í•œ ë²ˆë§Œ ë¡œë“œí•˜ë„ë¡ ì„¤ì •
# 1. gemini model 
if "model" not in st.session_state:
    st.session_state.model = load_model()

# 2. embedding model
if "embedding" not in st.session_state:
    st.session_state.embedding = load_embedding()

# ì„¸ì…˜ì˜ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
    
if "topic" not in st.session_state:
    st.session_state.topic = ""


# 1. ì´ ì£¼ì œë¡œ Vectorstore ë§Œë“¤ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
topic = st.text_input('ì°¾ì„ ë¬¸ì„œì˜ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”. ì˜ˆì‹œ) í‘ë°±ìš”ë¦¬ì‚¬: ìš”ë¦¬ ê³„ê¸‰ ì „ìŸ(ì‹œì¦Œ 1)')

if st.button('ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°'):
    if topic:
        vectorstore = create_vectorstore(topic)
        st.session_state.vectorstore = vectorstore    
        st.session_state.topic = topic
    else:
        st.warning('ì£¼ì œë¥¼ ì…ë ¥í•´ë¼', icon="âš ï¸")
    
if st.session_state.topic and st.session_state.vectorstore:    
    st.write(f"ì£¼ì œ: '{st.session_state.topic}' ë¡œ Vectorstore ì¤€ë¹„ì™„ë£Œ")
    
    
# 2. ì‚¬ìš©ì ì§ˆë¬¸ì— ìœ ì‚¬í•œ ë‚´ìš©ì„ Vectorstoreì—ì„œ RAG ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€
user_query = st.text_input('ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.')

if st.button('ì§ˆë¬¸í•˜ê¸°') and user_query:
    # ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
    st.session_state.chat_history.append(f"[user]: {user_query}")
    st.text(f'[You]: {user_query}')    

    # response = st.session_state.model.generate_content(user_querie)
    # model_response = response.candidates[0].content.parts[0].text
        
    # ëª¨ë¸ ì‘ë‹µ RAG
    if st.session_state.vectorstore:    
        response, context_docs = rag_chatbot(user_query)        
        st.text(f'[Chatbot]: {response}')
        st.text(f'ì¶œì²˜ ë¬¸ì„œ:\n')        
        st.write(context_docs)
    else: 
        response = "vector store is not ready."
        st.text(f'[Chatbot]: {response}')
    
    # ëª¨ë¸ ì‘ë‹µì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
    st.session_state.chat_history.append(f"[chatbot]: {response}")
    
    # ì „ì²´ íˆìŠ¤í† ë¦¬ ì¶œë ¥
    st.text("Chat History")
    st.text('--------------------------------------------')
    st.text("\n".join(st.session_state.chat_history))
